{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3811e33-e269-4a2e-b9ab-c577889a00ed",
   "metadata": {},
   "source": [
    "## The generalized code that works with all folders at the same time! (y=0, y=1, y=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f4f55-084a-4bcb-b0d4-d9a42c643f3b",
   "metadata": {},
   "source": [
    "### Jaber's Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a80a1d0-3bcb-40ee-b730-405c36847407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_10c.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_15c.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_34s.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_43s.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_45s.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_58c.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_62c.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the main directory paths\n",
    "#main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\01 Jaber'\n",
    "main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\01 Mariana'\n",
    "output_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files'\n",
    "\n",
    "# Define the mapping function for the second column\n",
    "def map_value(value):\n",
    "    mapping = {0: 30, 1: 60, 2: 90, 3: 120, 4: 150, 5: 180, 6: 210, 7: 240}\n",
    "    floor_value = int(value)\n",
    "    ceil_value = floor_value + 1\n",
    "    if floor_value in mapping and ceil_value in mapping:\n",
    "        mapped_value = (mapping[ceil_value] - mapping[floor_value]) * (value - floor_value) + mapping[floor_value]\n",
    "    else:\n",
    "        mapped_value = value  # Default to original value if out of bounds\n",
    "    return mapped_value\n",
    "\n",
    "# Get a list of all subdirectories in the main directory\n",
    "subdirectories = [f.path for f in os.scandir(main_directory_path) if f.is_dir()]\n",
    "\n",
    "# Loop over each subdirectory and process the files\n",
    "for subdir in subdirectories:\n",
    "    # Define the pattern to match the .csv files in the current subdirectory\n",
    "    file_pattern = f'{subdir}\\\\*.csv'\n",
    "    \n",
    "    # Get a list of all .csv files matching the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Initialize lists to hold the concatenated data\n",
    "    all_time = []\n",
    "    all_values = []\n",
    "\n",
    "    # Initialize the cumulative time with zero (for the first file)\n",
    "    cumulative_time = 0\n",
    "\n",
    "    # Loop over all files and process each one\n",
    "    for i, file in enumerate(file_list):\n",
    "        # Read the current .csv file\n",
    "        df = pd.read_csv(file, header=None)\n",
    "        \n",
    "        # Get the time and values columns\n",
    "        time = df[0].values\n",
    "        values = df[1].values\n",
    "        \n",
    "        if i == 0:\n",
    "            # For the first file, just append the time and values directly\n",
    "            all_time.extend(time)\n",
    "            all_values.extend(values)\n",
    "            \n",
    "            # Set the cumulative time to the last time value of the first file\n",
    "            cumulative_time = time[-1]\n",
    "        else:\n",
    "            # Adjust the time column by adding the last value of the previous cumulative time\n",
    "            adjusted_time = cumulative_time + time\n",
    "            \n",
    "            # Update the cumulative time for the next file\n",
    "            cumulative_time = adjusted_time[-1]\n",
    "            \n",
    "            # Append the adjusted time and values to the lists\n",
    "            all_time.extend(adjusted_time)\n",
    "            all_values.extend(values)\n",
    "    \n",
    "    # Map the values in the second column using the defined mapping\n",
    "    mapped_values = [map_value(value) for value in all_values]\n",
    "\n",
    "    # Create a DataFrame from the concatenated data\n",
    "    result_df = pd.DataFrame({\n",
    "        'Time': all_time,\n",
    "        'Values': mapped_values\n",
    "    })\n",
    "\n",
    "    # Determine the output file name based on the current subdirectory name\n",
    "    subdir_name = os.path.basename(subdir)\n",
    "    output_file = f'{output_directory_path}\\\\Signal_{subdir_name}.csv'\n",
    "    \n",
    "    # Save the result to a new .csv file\n",
    "    result_df.to_csv(output_file, index=False, header=False)\n",
    "\n",
    "    print(f'Results saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42697b-a17a-4e7f-9892-4d9521e6a48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79178fb1-626d-4b56-9e13-f3b6653eb6bb",
   "metadata": {},
   "source": [
    "### Celeste logic (y=1, y=2, y=3) so we substract BPMs from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d80dfa4-df58-4616-ab9e-732e90c4365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_14c.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_40s.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_44s.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_49s.csv\n",
      "Results saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files\\Signal_56c.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the main directory paths\n",
    "#main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\02 Melanie'\n",
    "#main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\02 Samantha'\n",
    "#main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\02 Lauren'\n",
    "#main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\02 Celeste'\n",
    "main_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Shands_Samples\\Converted\\02 Rayan'\n",
    "output_directory_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\Files'\n",
    "\n",
    "# Define the mapping function for the second column\n",
    "def map_value(value):\n",
    "    mapping = {0: 30, 1: 60, 2: 90, 3: 120, 4: 150, 5: 180, 6: 210, 7: 240}\n",
    "    floor_value = int(value)\n",
    "    ceil_value = floor_value + 1\n",
    "    if floor_value in mapping and ceil_value in mapping:\n",
    "        mapped_value = (mapping[ceil_value] - mapping[floor_value]) * (value - floor_value) + mapping[floor_value]\n",
    "    else:\n",
    "        mapped_value = value  # Default to original value if out of bounds\n",
    "    return mapped_value\n",
    "\n",
    "# Get a list of all subdirectories in the main directory\n",
    "subdirectories = [f.path for f in os.scandir(main_directory_path) if f.is_dir()]\n",
    "\n",
    "# Loop over each subdirectory and process the files\n",
    "for subdir in subdirectories:\n",
    "    # Define the pattern to match the .csv files in the current subdirectory\n",
    "    file_pattern = f'{subdir}\\\\*.csv'\n",
    "    \n",
    "    # Get a list of all .csv files matching the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Initialize lists to hold the concatenated data\n",
    "    all_time = []\n",
    "    all_values = []\n",
    "\n",
    "    # Initialize the cumulative time with zero (for the first file)\n",
    "    cumulative_time = 0\n",
    "\n",
    "    # Loop over all files and process each one\n",
    "    for i, file in enumerate(file_list):\n",
    "        # Read the current .csv file\n",
    "        df = pd.read_csv(file, header=None)\n",
    "        \n",
    "        # Get the time and values columns\n",
    "        time = df[0].values\n",
    "        values = df[1].values\n",
    "        \n",
    "        if i == 0:\n",
    "            # For the first file, just append the time and values directly\n",
    "            all_time.extend(time)\n",
    "            all_values.extend(values)\n",
    "            \n",
    "            # Set the cumulative time to the last time value of the first file\n",
    "            cumulative_time = time[-1]\n",
    "        else:\n",
    "            # Adjust the time column by adding the last value of the previous cumulative time\n",
    "            adjusted_time = cumulative_time + time\n",
    "            \n",
    "            # Update the cumulative time for the next file\n",
    "            cumulative_time = adjusted_time[-1]\n",
    "            \n",
    "            # Append the adjusted time and values to the lists\n",
    "            all_time.extend(adjusted_time)\n",
    "            all_values.extend(values)\n",
    "    \n",
    "    # Subtract 1 from all values in the second column\n",
    "    all_values = [value - 1 for value in all_values]\n",
    "\n",
    "    # Map the values in the second column using the defined mapping\n",
    "    mapped_values = [map_value(value) for value in all_values]\n",
    "\n",
    "    # Create a DataFrame from the concatenated data\n",
    "    result_df = pd.DataFrame({\n",
    "        'Time': all_time,\n",
    "        'Values': mapped_values\n",
    "    })\n",
    "\n",
    "    # Determine the output file name based on the current subdirectory name\n",
    "    subdir_name = os.path.basename(subdir)\n",
    "    output_file = f'{output_directory_path}\\\\Signal_{subdir_name}.csv'\n",
    "    \n",
    "    # Save the result to a new .csv file\n",
    "    result_df.to_csv(output_file, index=False, header=False)\n",
    "\n",
    "    print(f'Results saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f656e45-1623-4347-9923-92f68a2cc58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17befb8e-36b8-4d0b-851b-22984f79f8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa15701-79df-4259-b082-ec36ec025dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e0f0b89-dd87-4436-b7bb-f94d00e59239",
   "metadata": {},
   "source": [
    "# Merging all files in a united Spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65267b32-a88b-4bfe-b354-ca0fac6f4b12",
   "metadata": {},
   "source": [
    "#### Outputs: .csv and .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71779a81-417c-49b4-8400-0ca771669b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\n",
      "Combined TXT file saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "input_directory = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\All_files_ready_to_be_a_long_Spreadsheet\"\n",
    "output_csv_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\"\n",
    "output_txt_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.txt\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate over all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, header=None, names=['Time', 'BPM'])\n",
    "        \n",
    "        # Extract the instance number from the filename\n",
    "        instance_number = filename.split('.')[0]\n",
    "        \n",
    "        # Transpose the BPM column and set the index to instance_number\n",
    "        bpm_values = pd.DataFrame(df['BPM'].values).transpose()\n",
    "        bpm_values.index = [instance_number]\n",
    "        \n",
    "        # Append to the combined DataFrame\n",
    "        data_frames.append(bpm_values)\n",
    "\n",
    "# Combine all the DataFrames\n",
    "combined_df = pd.concat(data_frames)\n",
    "\n",
    "# Save the combined DataFrame to the output CSV file\n",
    "combined_df.to_csv(output_csv_file, index_label='Instance', header=False)\n",
    "\n",
    "# Save the combined DataFrame to the output TXT file\n",
    "combined_df.to_csv(output_txt_file, index_label='Instance', header=False, sep=',')\n",
    "\n",
    "print(f\"Combined CSV file saved to {output_csv_file}\")\n",
    "print(f\"Combined TXT file saved to {output_txt_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d46fd9-cd70-44a5-9b87-d487514c9f8a",
   "metadata": {},
   "source": [
    "#### Output: .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71e557-ebdf-4d59-b8df-04e868a83a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "input_directory = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\All_files_ready_to_be_a_long_Spreadsheet\"\n",
    "output_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate over all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, header=None, names=['Time', 'BPM'])\n",
    "        \n",
    "        # Extract the instance number from the filename\n",
    "        instance_number = filename.split('.')[0]\n",
    "        \n",
    "        # Transpose the BPM column and set the index to instance_number\n",
    "        bpm_values = pd.DataFrame(df['BPM'].values).transpose()\n",
    "        bpm_values.index = [instance_number]\n",
    "        \n",
    "        # Append to the combined DataFrame\n",
    "        data_frames.append(bpm_values)\n",
    "\n",
    "# Combine all the DataFrames\n",
    "combined_df = pd.concat(data_frames)\n",
    "\n",
    "# Save the combined DataFrame to the output file\n",
    "combined_df.to_csv(output_file, index_label='Instance', header=False)\n",
    "\n",
    "print(f\"Combined CSV file saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072772b-5db9-4cdb-876c-9dad0f040820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b277e72-9c81-41c5-9527-800f49a30018",
   "metadata": {},
   "source": [
    "### ALSO included \"label\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e647241-08b1-415a-982f-2c5e5c451ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\n",
      "Combined TXT file saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "input_directory = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\All_files_ready_to_be_a_long_Spreadsheet\"\n",
    "output_csv_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\"\n",
    "output_txt_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.txt\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate over all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, header=None, names=['Time', 'BPM'])\n",
    "        \n",
    "        # Extract the instance number from the filename\n",
    "        instance_number = filename.split('.')[0]\n",
    "        \n",
    "        # Create a DataFrame with BPM values and set the index to instance_number\n",
    "        bpm_values = pd.DataFrame(df['BPM'].values).transpose()\n",
    "        bpm_values.index = [instance_number]\n",
    "        \n",
    "        # Append to the combined DataFrame\n",
    "        data_frames.append(bpm_values)\n",
    "\n",
    "# Combine all the DataFrames\n",
    "combined_df = pd.concat(data_frames)\n",
    "\n",
    "# Save the combined DataFrame to the output CSV file\n",
    "combined_df.to_csv(output_csv_file, index_label='Instance', header=False)\n",
    "\n",
    "# Save the combined DataFrame to the output TXT file with comma-separated values\n",
    "combined_df.to_csv(output_txt_file, index_label='Instance', header=False, sep=',')\n",
    "\n",
    "print(f\"Combined CSV file saved to {output_csv_file}\")\n",
    "print(f\"Combined TXT file saved to {output_txt_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7ccaf-2fff-4e56-9882-a5aa47f5c020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabfb3a6-bd37-4afd-8239-b95a2b242920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved to C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "input_directory = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\All_files_ready_to_be_a_long_Spreadsheet\"\n",
    "output_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\combined_BPM_data.csv\"\n",
    "labels_file = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\Research\\FHRT\\PROJECT\\Data_Results\\Concatenated\\labells.csv\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate over all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, header=None, names=['Time', 'BPM'])\n",
    "        \n",
    "        # Extract the instance number from the filename\n",
    "        instance_number = filename.split('.')[0]\n",
    "        \n",
    "        # Transpose the BPM column and set the index to instance_number\n",
    "        bpm_values = pd.DataFrame(df['BPM'].values).transpose()\n",
    "        bpm_values.index = [instance_number]\n",
    "        \n",
    "        # Append to the combined DataFrame\n",
    "        data_frames.append(bpm_values)\n",
    "\n",
    "# Combine all the DataFrames\n",
    "combined_df = pd.concat(data_frames)\n",
    "\n",
    "# Read the labels file\n",
    "labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "# Set the index of the labels DataFrame to \"Patient\" to align with the combined DataFrame\n",
    "labels_df.set_index('Patient', inplace=True)\n",
    "\n",
    "# Add the \"label\" column to the combined DataFrame\n",
    "combined_df['label'] = labels_df['label']\n",
    "\n",
    "# Create a header row\n",
    "header = ['Patient'] + list(map(str, range(1, combined_df.shape[1]))) + ['label']\n",
    "\n",
    "# Insert the header row at the top of the DataFrame\n",
    "combined_df.columns = header[:-1]  # Update column names excluding the last column\n",
    "combined_df.reset_index(inplace=True)\n",
    "combined_df.columns = header  # Update column names including the last column\n",
    "\n",
    "# Save the combined DataFrame to the output file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined CSV file saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31830f-ee5f-4551-9805-65a91876c1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
